\section{Decentralized Control of Flow Networks}
\label{sec:admm-intro}

Finite-horizon optimal control is a popular method for computing predictive control strategies for dynamical systems~\cite{Reilly2013AdjointBased,Bayen2006AdjointBased}, its applicability growing with the increase of computational power and pervasiveness of physical sensing. In general, a finite-horizon optimal control problem will take the following form:

\begin{align}
  \label{eq:fhop}
  \min_{x\in X} & \quad f\left(s, x\right) \\
  \text{subject to:} & \quad s = g\left(x\right)
\end{align}

where $x$ represents the vector of control variables belonging to the set of feasible controls $X$ (which we may assume to be $\Re^n$ for simplicity), $s$ represents the vector of ``state'' variables, constrained to be a deterministic function $g\left(x\right)$ of the control, and $f$ is some objective function of the control and state we wish to minimize.

\paragraph*{Related Work in Distributed Optimization}
Much attention has recently been given to distributed methods for finite-horizon optimal control problems, where $g$ is assumed to be linear and $f$ is assumed to be quadratic or convex. Distributed optimization has been found useful for at least two reasons. Firstly, the parallelizability of the individual sub-problems allows for faster computation time and better overall convergence properties~\cite{Donoghue2013Splitting,Frejo2011,Pu2014Fast,Giselsson2013Accelerated}. Secondly, physical systems often have controls physically distributed in space, creating a need for distributed control algorithms which limit the amount of shared information and communication between subsystems~\cite{mota2012distributed,camponogara2009distributed,Venkat2008Distributed}.

Different assumptions on the structure, smoothness, and convexity of $f$, $X$ and $g$ leads to different convergence bounds and communication bounds. In optimal control, a method presented in~\cite{Donoghue2013Splitting} for decoupling the quadratic terms from the nonquadratic terms leads to efficient caching techniques shown to be effective in FPGA applications. A distributed gradient descent-based approach is given in~\cite{camponogara2009distributed}, which has $O\left(\frac{1}{\sqrt{k}}\right)$ convergence to the global optimum in the general case, where $k$ is the number of iterations of the algorithm.  A common dual-decomposition technique employed for distributed optimal control is the \emph{alternating directions method of multipliers}~\cite{gabay1976dual,Boyd2010a,Donoghue2013Splitting} (ADMM), which has been shown to have $O\left(\frac{1}{k}\right)$ convergence under certain assumptions of the smoothness and decomposability of the objectives~\cite{Wei2013On}. Additionally, an accelerated version of ADMM, based on Nesterov's algorithm~\cite{Nesterov1983Method} can give $O\left(\frac{1}{k^2}\right)$ convergence when the decomposed objectives are smooth~\cite{Pu2014Fast}.

When the coupling between systems takes on some sparse form, then one can devise algorithms with limited communication, which can be beneficial from a latency and  architectural standpoint. Optimal control problems where subsystems have disjoint state variables but coupled control variables have been shown to be amenable to decomposition techniques for distributed optimization~\cite{Giselsson2013Accelerated,camponogara2009distributed}, where~\cite{mota2012distributed} shows how ADMM decomposition leads to less communication without a decrease in solution accuracy.

In~\cite{mota2012distributed,Giselsson2013Accelerated,camponogara2009distributed}, the subsystems with disjoint state are modeled as agents tasked with optimizing over their own subsystem, where agents which share some control variables are connected by some edge in a communication graph. Thus, the more sparse the coupling of systems, the lesser the communication requirements. Such a model is referred to as \emph{multi-agent optimization}~\cite{Wei2013On}. In systems with coupling due to physical proximity, this consequence has the added benefit of requiring only physically local communication, and removes the need for any centralized controller or hub for communication. In~\cite{Wei2013On}, an asynchronous form of ADMM (subsequently referred to as A-ADMM) is presented for multi-agent optimization, which permits agents to update themselves in arbitrary order, with communication only required between neighboring agents. The method in~\cite{Wei2013On} does not present an accelerated version and is shown to have $O\left(\frac{1}{k}\right)$ convergence.

\paragraph*{Subsystems with Coupled State}
One recurring assumption in the distributed optimization literature above is that subsystems have disjoint state variables. For network flow problems, where subsystems correspond to partitions of a network into subnetworks, such an assumption does not hold. To see this, one can imagine a traffic light timing plan causing a traffic jam which spreads across the entire freeway network~\cite{Reilly2013AdjointBased,Muralidharana} or a bottleneck of planes in an airspace affecting flight times throughout the air network~\cite{Bayen2006AdjointBased}. As a result, it is not possible to decompose the subsystems by only sharing control parameters without coupling each subsystem to all control variables and modeling the evolution of the entire network within each subsystem.

Yet, freeway traffic and air traffic subsystems have a very sparse coupling in their state variables. For instance, discrete traffic models~\cite{daganzo1995cell,delle2014pde} often assume that the speed of traffic on a particular section of road is only a function of the speed of traffic on neighboring links. Thus, each subnetwork subsystem would only share a small number of control variables and state variables with other subsystems, precisely those which physically share a border with the subsystem.

To exploit the sparsity of such systems, we develop a multi-agent optimization algorithm based on A-ADMM~\cite{Wei2013On} which permits each agent (subsystem) to share both control and state variables with neighboring agents, while still converging to the globally optimal control, given the standard assumption of convex objectives and linear constraints. At a high level, the algorithm ``relaxes'' the state variables \emph{external} to an agent while constraining \emph{internal} state variables to adhere to the subsystem's dynamics. Since A-ADMM eventually brings all shared variables between agents into \emph{consensus} (i.e. the difference between shared variables converges to zero), the relaxed external state variables will converge to satisfying the original constraints.

The rest of the section is structured as follows. Section~\ref{sec:problem_statement} presents the general problem of posing a multi-agent optimal control problem, with the additional assumption that an agent may share both state and control variables with other agents. The problem is then posed in a form amenable to using the A-ADMM algorithm in Section~\ref{sec:algorithm}. A systematic approach to modeling an optimal control problem over a dynamical network as a multi-agent distributed optimization over subnetworks is given in Section~\ref{sec:distributed_optimization_of_coupled_dynamical_systems}, as well as a discussion on the suitability of the method for scaling model predictive control on dynamical networks. In Section~\ref{sec:minimizing_sub_objectives_using_the_adjoint_method}, we give an adjoint-based approach to solving the agent's subnetwork optimal control problem, suitable for applications with complex, non-convex dynamics. We then present the application of distributed, predictive ramp-metering and variable speed limit (VSL) control on freeway networks in Section~\ref{sec:ramp-metering-admm} followed by numerical results in Section~\ref{sec:numerical_results-admm} with comparisons to existing distributed approaches.

\paragraph*{\textbf{Notation}}

For a vector $x$, let $x\left[i\right]$ be the $i$'th element of $x$, and similarly let $y\left[i,j\right]$ be the element of the two-dimensional vector in the $i$'th row and $j$'th column. If we have a vector $x$ with $card\left(x\right)=N$ and let $w$ be a subset of $ \{1,\ldots,N\}$, then let $x_w$ denote the vector selecting only those elements $x\left[i\right]$ where $i\in w$. If a vector $d$ is the concatenation $d = \left(a,b,c\right)$, then let $\left[d\right]_a$ be the sub-vector of $d$ corresponding to the original element $a$.


\subsection{Optimization over Systems with Shared State}
\label{sec:problem_statement}

We wish to solve an optimization problem with a ``free'' global variable $x \in \Re^n$ and a ``dependent'' variable $s \in \Re^m$ which is a deterministic function of $x$.
We assume there is a partition of $s$ into $D$ disjoint subsets,
\[
s=\left(s_{u\left(1\right)},\ldots,s_{u\left(D\right)}\right),
\] where $u\left(i\right)$ are subsets of $ \{1,\ldots,m\} $.
The objective function is assumed to be the sum of $D$ sub-objectives, where sub-objective $f_i, i\in \{1,\ldots,D\} $ is a convex function of only variable $s_{u\left(i\right)}$.~\footnote{We omit the dependency of the objective on the control variable in this presentation for simplicity. It is still easy in this form to add control variables into the objective by duplicating a control variable into the state.}
Furthermore, $s_{u\left(i\right)}$ is assumed to be a function of some subset of $x$ and $s$.
Explicitly, for each $i\in {1,\ldots, D} $, there is well-defined, linear function $g_i$ and subsets $v\left(i\right)$ and $w\left(i\right)$ ($w\left(i\right) \cap u\left(i\right) = \emptyset$) where 
\begin{equation}
\label{eqn:s-g-rel}
s_{u\left(i\right)} = g_i\left(\left(x_{v\left(i\right)}, s_{w\left(i\right)}\right)\right).
\end{equation}
The tuple $\left(x_{v\left(i\right)}, s_{w\left(i\right)}\right)$ is the concatenation vector of $x_{v\left(i\right)}$ and $s_{w\left(i\right)}$.
We omit the double parenthesis in the rest, for simplicity. One can view $u\left(i\right), v\left(i\right), w\left(i\right), $ as the \emph{internal} state, the control, and the \emph{external} state, respectively, of group $i$. 
We can now express the optimization problem we wish to solve as:

\begin{align}
  \label{eq:problem-statement}
  \min_{x,s} & \quad \sum_{i = 1}^D f_i\left(s_{u\left(i\right)}\right) \\
  \text{subject to:} & \quad s_{u\left(i\right)} = g_i\left(x_{v\left(i\right)}, s_{w\left(i\right)}\right) \quad \forall i
\end{align}

Figure~\ref{sub:dep-graph-diagram} shows an example of how different sub-objectives may be coupled and Table~\ref{tab:dep-graph-subsets} summarizes how one constructs the $u\left(i\right), v\left(i\right), w\left(i\right)$ subsets from the state and control coupling.

\begin{figure}[t]
\centering
  \subfloat[Free and dependent variable coupling diagram.]{
  \label{sub:dep-graph-diagram}%
  \includegraphics[width=.43\columnwidth]{previous-articles/admm/figures/dep-graph}%
  } \hfill
  \subfloat[Summary of resultant state, control, and external state subsets.]{
  \footnotesize%
    \begin{tabular}[b]{|l|c|c|c|}
    \hline
    Group $i$ & $u\left(i\right)$ & $v\left(i\right)$ & $w\left(i\right)$\\ \hline
    $i=1$ & \{1,2\}       & \{1\}        & \{\}        \\ \hline
    $i=2$ & \{3\}        & \{1,2\}       & \{4,5\}       \\ \hline
    $i=3$ & \{4,5\}        & \{3\}       & \{3\}       \\ \hline
    \end{tabular}\label{tab:dep-graph-subsets}}\\
    \subfloat[Summary of shared control and state between groups]{
    \centering
    \begin{tabular}{|l|c|c|c|}
\hline
Edge $\left(i,j\right)$ & $v\left(i\right) \cap v\left(j\right)$ & $u\left(i\right) \cap w\left(j\right)$ & w$\left(i\right) \cap u\left(j\right)$  \\ \hline
$i,j=1,2$ & \{1\}       & \{\}        & \{\}        \\ \hline
$i,j=2,3$ & \{\}        & \{3\}       & \{4,5\}       \\ \hline
$i,j=1,3$ & \{\}        & \{\}       & \{\}       \\ \hline
\end{tabular}
\label{tab:dep-graph-edges}
    }
    \caption[Example of optimization problem partitioned into $D=3$ disjoint state variable groups with shared control and external state variables.]{Example of optimization problem partitioned into $D=3$ disjoint state variable groups with shared control and external state variables. Figure~\ref{sub:dep-graph-diagram} shows the partitioned problem, where an arrow depicts a dependency of a partition group on an external state variable or control variable. The arrows allow us to compute the $u\left(i\right), v\left(i\right), w\left(i\right)$ subsets for each group $i$, where $\rightarrow$ indicates functional dependency through Equation~\ref{eqn:s-g-rel}. Table~\ref{tab:dep-graph-subsets} summarizes the construction. The dependency graph $(V,E)$ is computed using the subsets in Table~\ref{tab:dep-graph-subsets}, which is summarized in Table~\ref{tab:dep-graph-edges} and reveals that edges exist for groups $\left(1,2\right)$ and $\left(2,3\right)$, but not for $\left(1,3\right)$.}
    \label{fig:dep-graph}
  \end{figure}


\paragraph*{Dependency Graph}

There are no assumptions on the subsets $v\left(i\right)$ and $w\left(i\right)$, which implies that the value of each sub-objective $f_i$ is coupled to not just the sub-vector $s_{u\left(i\right)}$, but also the global variable $x$, and other sub-vectors $s_{u\left(j\right)}$. We can express this coupling as a dependency graph $\left(V,E\right)$, where vertices $V$ are each sub-problem $i\in \{1,\ldots, D\} $ and an edge $\left(i,j\right)\in E$ exists whenever

\begin{enumerate}
  \item  $w\left(i\right) \cap u\left(j\right) \neq \emptyset$ ($g_i$ is a function of some variable in $s_{u\left(j\right)}$), \textbf{or}
  \item $v\left(i\right) \cap v\left(j\right) \neq \emptyset$ (there is some $x\left[k\right]$ which both $g_i$ and $g_j$ depend upon).
\end{enumerate}
 
Let the neighboring edges of node $i\in V$ be denoted by $E\left(i\right)$. A dependency graph construction for the example in Figure~\ref{sub:dep-graph-diagram} is summarized in Table~\ref{tab:dep-graph-edges}.

In Section~\ref{sec:algorithm}, we devise a distributed algorithm solve Problem~\eqref{eq:problem-statement} with the following requirements:

\begin{enumerate}
  \item Each processing node corresponds to a sub-objective node in the dependency graph.
  \item Each node can be updated in parallel.
  \item Each node $i$ only exchanges information with its neighbors $E\left(i\right)$ in the dependency graph $\left(V,E\right)$.
  \item The algorithm is asynchronous and decentralized, i.e. no central process is required and nodes can be updated arbitrarily.
\end{enumerate}

% section problem_statement (end)

\subsection{Asynchronous-ADMM Algorithm} % (fold)
\label{sec:algorithm}

We reformulate Problem~\eqref{eq:problem-statement} to permit a distributed solution method via A-ADMM.  For each node $i\in V$, we duplicate the ``shared variables'' $x_{v\left(i\right)}$ and $s_{w\left(i\right)}$ as $\bar{x}_i$ and $\bar{s}_i$ respectively, and reformulate Problem~\eqref{eq:problem-statement} as:

\begin{align}
  \label{eq:duplicate-problem-statement}
  \min_{x} & \quad \sum_{i = 1}^D f_i\left(s_{u\left(i\right)}\right) \\
  \text{subject to:} & \quad s_{u\left(i\right)} = g_i\left(\bar{x}_i, \bar{s}_i\right) \quad \forall i  \label{eqn:state-constraint-decoupled} \\
   & \quad \bar{s}_i = s_{w\left(i\right)} \quad \forall i \label{eqn:state-consensus} \\
   & \quad \bar{x}_i = x_{v\left(i\right)} \quad \forall i \label{eqn:control-consensus} 
\end{align}

The variable replication allows Constraint~\eqref{eqn:state-constraint-decoupled} in Problem~\eqref{eq:duplicate-problem-statement} to be decoupled across nodes. To decouple Constraints~\eqref{eqn:state-consensus} and~\eqref{eqn:control-consensus}, we follow a modified process from~\cite{Wei2013On}.

First, we duplicate each subset $s_{u\left(i\right)}$ with a vector $s_i$ local to node $i \in V$, and then concatenate all local variables into a single variable $y_i = \left(s_i, \bar{x}_i, \bar{s}_i\right)$, such that $y_i$ is restricted to the space:
\[
Y_i = \{\left(s_i,\bar{x}_i, \bar{s}_i\right) : s_i = g_i\left(\bar{x}_i, \bar{s}_i\right)\}.
\]
Finally, we can repose Constraints 2 and 3 in an \emph{edge-wise} fashion as follows. For each edge $e = \left(i,j\right) \in E$, let $y_{i,e}$ and $y_{j,e}$ be the sub-vectors of $y_i$ and $y_j$ that are coupled through $g_j$ and $g_i$, respectively. Then Problem~\eqref{eq:problem-statement} becomes:

\begin{align}
  \label{eq:edge-problem-statement}
  \min_{(y_i \in Y_i)_{i \in V}} & \sum_{i = 1}^D f_i\left(\left[y_i\right]_{s}\right) \\
  \text{subject to:} & \quad y_{i,e} = y_{j,e} \quad \forall e\in E
\end{align}

By moving the edge constraints into the objective through a standard Lagrange multiplier approach, and adding a regularization term which is equal to zero for feasible solutions~\cite{Boyd2010a}, we can construct the augmented Lagrangian $\mathcal{L}$ formulation (with tunable augmenting coefficient $\augterm$), and express the optimization problem as:
% \vspace{-2.5pt}
\begin{align}
  \label{eq:lagrangian}
  \min_{y = (y_i)_{i \in V}} \max_{\lambda = \left(\lambda_e\right)_{e \in E}} & \mathcal{L} \left(y,\lambda\right) := \sum_{i = 1}^D f_i\left(\left[y_i\right]_{s}\right) + \sum_{e\in E} \lambda_e^T \left(y_{i,e} - y_{j,e}\right) + \augterm \|y_{i,e} - y_{j,e}\|_2^2,
\end{align}

\begin{algorithm}[t]  % enter the algorithm environment
\caption{Asynchronous Edge Based ADMM} % give the algorithm a caption
\label{alg:a-admm}       % and a label for \ref{} commands later in the document
\begin{algorithmic}[1]% enter the algorithmic environment
    \WHILE{Not Converged}
    \STATE Select edge $\left(i,j\right) \in E$
        \FOR{$q \in \left(i,j\right)$}
        \STATE $y^{k+1}_q \gets \arg \min_{y \in Y_q} f_q\left(\left[y\right]_{s}\right) - \sum_{e \in E\left(q\right)} \Lambda_{q,e} \lambda^{k,T}_{e} \left(y_{q,e} - \bar{y}^{k}_{e} \right) + \frac{\augterm}{2} \|y_{q,e} - \bar{y}^{k}_{e}\|_2^2 \label{lst:local-state-update}$
        \ENDFOR
        \STATE $\lambda^{k+1}_{e} \gets \lambda^{k+1}_{e} - \frac{\augterm}{2} \left(y^{k+1}_{i,e} - y^{k+1}_{j,e}\right)$
        \FOR{$q \notin \left(i,j\right)$}
        \STATE $a^{k+1} \gets a^{k}$
        \ENDFOR
    \ENDWHILE
    \STATE Note: $\tilde{y}^{k}_{e} = \frac{1}{2} \left(y^k_{i,e} + y^k_{j,e}\right)$
    \STATE Note: $\Lambda_{q,e} = \begin{cases} 1 & \quad q = i \\ -1 & \quad q = j \end{cases} \quad e = (i,j)$
\end{algorithmic}
\end{algorithm}
  
The above form permits us to apply the A-ADMM algorithm as proposed and analyzed in~\cite{Wei2013On}, and shown in Algorithm~\ref{alg:a-admm}. At a high-level, the algorithm iterates by first randomly selecting an edge $e = \left(i,j\right)$ from $E$. Then, nodes $i$ and $j$ update $y_i$ and $y_j$ respectively by minimizing the Lagrangian in Equation~\eqref{eq:lagrangian} in parallel, while holding all other variables $\{\lambda_e'\}_{e' \neq e}, \{y_k\}_{i\notin \{i,j\}}$ constant. The new $y_i$ and $y_j$ values are used to update the dual $\lambda_e$ variables by applying a dual-ascent method~\cite{Boyd2010a}. Finally, the process is repeated \emph{ad-infinitum} by updating a new edge selected from $E$, until some convergence or termination criteria are reached.

Section~\ref{sec:minimizing_sub_objectives_using_the_adjoint_method} presents an efficient solution method, based on discrete adjoint computations, to solving the subproblem on Line 4 of Algorithm~\ref{alg:a-admm}.

\begin{remark} The equation in Line~\ref{lst:local-state-update} differs slightly from the augmented Lagrangian in Equation~\eqref{eq:lagrangian} and is the result of a number of algebraic manipulations, which are explicitly derived in~\cite{Boyd2010a,Wei2013On}.
\end{remark}
\begin{remark}
We introduce the asymmetric coefficient $\Lambda_{q,e}$ to account for the fact that the terms for edge $e\in E\left(q\right)$ in Line~\ref{lst:local-state-update} depend upon whether the updating problem $q$ was the first or second term ($i$ or $j$) in the edge pair.
\end{remark}


\subsection{Distributed Optimization on Coupled Dynamical Systems} % (fold)
\label{sec:distributed_optimization_of_coupled_dynamical_systems}

Physical transport systems, such as freeway traffic networks~\cite{Reilly2013AdjointBased,daganzo1995cell} or gas pipelines~\cite{Gugat2011Gas} are often naturally expressed as a network of individual dynamical systems which influence one another at contact points, or \emph{junction points}. Given the coupling in dynamics across the entire network, optimizing over partitioned sub-systems, with no communication between systems, will lead to \emph{greedy} solutions over the individual systems and sub-optimal global results~\cite{Frejo2011}. Thus, any distributed, globally optimal control scheme applied to such systems must account for the \emph{shared state} between the systems. We now show how this can be done using the multi-agent A-ADMM approach. Furthermore, we show how the algorithm naturally leads to a communication scheme which mirrors the physical structure of the underlying physical network.

Assume some discrete-time, discrete-space dynamical system which possesses a network-like dynamical coupling in space. Specifically, consider a graph $\left(V^d, E^d\right)$ (not to be confused with the dependency graph $\left(V,D\right)$ in Section~\ref{sec:problem_statement}, where the $d$ superscript is added to denote the \emph{dynamical} network) where $E^d$ represent the discrete-space \emph{cells} and $V^d$ are the \emph{junction points} where cells connect to one another, i.e. each cell in $E^d$ has a corresponding upstream and downstream junction both in $V^d$.  Each discrete space ``cell'' $c \in \{1,\ldots,N_d\} $ has for each discrete time step $k \in \{1,\ldots,T_d\} $ both a control variable $x\left[c,k\right] \in \Re$ and a state variable $s\left[c,k\right] \in \Re$. The variable $s\left[c,k\right]$ is assumed to be a function of all state and control variables that satisfy two conditions:

\begin{itemize}
  \item the time-step is $k-1$, and
  \item the cell must share a junction with cell $c$.
\end{itemize}

Next, we wish to express a distributed optimization problem subject to the above dynamics in the form of Problem~\eqref{eq:problem-statement}. To do so, we assume a partition of $\left(V^d,E^d\right)$ into $D$ \emph{sub-networks}, which implies a partition of $E^d$ into $D$ subsets $\left(E^d_1,\ldots, E^d_D\right)$ and assume an objective $f$ which is splittable across the state variables internal to each sub-network. This leads to a state partitioning $s=\left(s_{u\left(1\right)}, \ldots, s_{u\left(D\right)}\right)$, where $ \left(c,k\right) \in u\left(i\right)$ iff $c \in E^d_i$.

Based on the two conditions for state dependencies above, we can deduce that the state of a sub-network depends on the control and state both internal to the sub-network and directly \emph{neighboring} the sub-network. Explicitly, for sub-network $i$, we can express the dependent control variables as $x_{v\left(i\right)}$ where $\left(c,k\right)\in v\left(i\right)$ iff $c \in E^d_i$ or $c$ neighbors a cell in $E^d_i$. Similarly, the shared state for sub-network $i$ is $s_{w\left(i\right)}$, where $\left(c,k\right)\in w\left(i\right)$ iff $c \notin E^d_i$ and $c$ neighbors a cell in $E^d_i$. Finally, we conclude that there exists some update equation $g_i$, specific to the particular dynamical system, where the constraint on $s_{u\left(i\right)}$ can be expressed familiarly as $s_{u\left(i\right)} = g_i\left(x_{v\left(i\right)}, s_{w\left(i\right)}\right)$.

\begin{figure}
  \subfloat[Complete network]{
  \includegraphics[width=.23\columnwidth]{previous-articles/admm/figures/net-1}
  \label{subfig:net-1}
  } \hfill
  \subfloat[Solid subnetwork with two shared links]{
  \includegraphics[width=.23\columnwidth]{previous-articles/admm/figures/net-2}
  \label{subfig:net-2}
  }\hfill
  \subfloat[Dotted subnetwork with three shared links]{
  \includegraphics[width=.23\columnwidth]{previous-articles/admm/figures/net-3}
  \label{subfig:net-3}  
  } \hfill
  \subfloat[Dash-dotted subnetwork with three shared links]{
  \includegraphics[width=.23\columnwidth]{previous-articles/admm/figures/net-4}
  \label{subfig:net-4}  
  }
  \label{fig:net-example}
  \caption[A network partitioned into three subnetworks depicting internal vs. external cells for each subnetwork.]{A network is partitioned into three subnetworks: solid, dashed, and dash-dotted. Each subnetwork will share state with neighboring subnetworks. For a subnetwork $i$, the cells neighboring $i$, denoted by $E^d_i$, are shown in black, while those excluded from $E^d_i$ are shown in gray.}
\end{figure}

As an example, we can consider the network in Figure~\ref{subfig:net-1}, which is partitioned into three subnetworks based on line-style. We see that four of the edges share a single junction between the three subnetworks. Thus, the dynamics assumed above implies that each subnetwork will share state with each other subnetwork. Specifically, the solid-lined network in Figure~\ref{subfig:net-2} shares one cell each from the other two subnetworks, while the dashed and dash-dotted subnetworks in Figures~\ref{subfig:net-3} and~\ref{subfig:net-4} share two cells with the solid subnetwork and one cell with the opposite subnetwork. We note again that while each optimizing agent may have different values of the state on a particular cell in the network during intermediate stages of the A-ADMM algorithm, each copy of the state will eventually come into consensus as the shared-state A-ADMM algorithm converges.

\paragraph*{Local Communication Requirements}

At this point, all relevant parameters to Problem~\eqref{eq:problem-statement} have been specified. The assumption on the dynamical network coupling leads to a desirable dependency graph $\left(V,E\right)$ for the system above. Since each sub-network only requires shared state from neighboring sub-networks in the sense of the \emph{physical} network $\left(V^d,E^d\right)$, then the dependency graph $\left(V,E\right)$ is constructed by assigning a sub-network to each node $V$ and adding an edge $\left(i,j\right)$ to $E$ only for those sub-networks $i$ and $j$ which physically neighbor each other.  Thus, the A-ADMM algorithm guarantees that communication only take place between physically neighboring systems. This is useful for situations where there are limitations in the networking capabilities due to physical distance, such as freeway traffic control systems, where collaborations may only exist for those districts near each other.

Furthermore, the formulation allows for a completely decentralized and asynchronous implementation of the global optimization problem. If, for instance, all nodes are managed by independent agencies with varying computational limits, then there are several practical benefits to the approach. For a single sub-network, since only information that is directly adjacent to other sub-networks needs to be shared with other sub-networks, much of the internal formulation of the sub-network can be made completely hidden from the larger network. The asynchronicity of the algorithm also permits for neighboring agencies to exchange information in an ad-hoc manner, and not be bottlenecked by slower updates between separate sub-networks.

\paragraph*{Scalability of Subnetwork Splitting for Model Predictive Control}

A common application of finite-horizon optimal control is in the context of model predictive control (MPC)~\cite{Reilly2013AdjointBased,Frejo2011}, where optimal control policies are recomputed in a \emph{rolling-horizon} fashion. Given the optimal control problem beginning at a time-step $t$,
 
\begin{align}
  \label{eq:fhop-mpc}
  \min_{x = \{x_t,\ldots, x_{t + T}\}} & \quad f_t^{t + T}\left(s, x\right) \\
  \text{subject to:} & \quad s = g_t^{t + T}\left(x\right) \nonumber,
\end{align}

MPC chooses the control policy $x_t$ to apply at time-step $t$ by solving for $x = \{x_t,\ldots, x_{t + T}\}$ in Equation~\eqref{eq:fhop-mpc} using a prediction horizon of $T$ and updating the objective $f_t^{t+T}$ and constraints $g_{t}^{t + T}$ based on the latest estimates of the initial conditions and boundary conditions.

In applications such as freeway onramp metering, a limiting factor in choosing an optimization time-horizon is the accuracy of the predictions of the boundary conditions, or specifically, anticipating future vehicle demands on freeway onramps. At some point, increasing the time-horizon will only decrease the effectiveness of the control due to the deviation in predicted model state versus reality. Thus, it is often practical to consider the time-horizon fixed in MPC applications, at which point the scalability with respect to network size becomes of importance.

For freeway networks with very small branching factors, it is reasonable to assume the following:

\begin{itemize}
  \item For each subnetwork, the number of bordering links is \emph{constant}.
  \item The number of shared state and control variables grows \emph{linearly} with the time-horizon for each subnetwork.
  \item The number of subnetworks scales linearly with network size (for fixed-size subsystems).
\end{itemize}

 One concludes that the amount of communication required for the A-ADMM subnetwork splitting method would scale linearly with the network size and quadratically with time-horizon length. If we were to instead decompose our system, for instance, across time-slices, the communication requirement would scale quadratically with network size and linearly with time-horizon length. Given our assumption of a fixed time-horizon, the subnetwork splitting approach for network-flow MPC has the added benefit of better scaling in the communication requirements.

\subsection{Solving Sub-problems via the Adjoint Method} % (fold)
\label{sec:minimizing_sub_objectives_using_the_adjoint_method}

What is not explicitly expressed in Algorithm~\ref{alg:a-admm} is a solution method for Step~\ref{lst:local-state-update}:

\begin{align}
	\label{eq:sub-op-problem}
	y^{k+1}_i = \arg \min_{y \in Y_i}
        f_i\left(\left[y\right]_{s}\right) - 
        \sum_{e \in E\left(i\right)}
        \Lambda_{i,e} \lambda^{k,T}_{e} \left(y_{i,e} - \bar{y}^{k}_{e} \right) +
        \frac{\augterm}{2} \|y_{i,e} - \bar{y}^{k}_{e}\|_2^2
\end{align}
In the more general case of non-convex update equations $g_i$ and objectives $f_i$, it is difficult to find even local optima for $y_i$ over the space $Y_i$ using gradient-descent methods: a result of the difficulty of projecting and expensiveness of computing gradients in $Y_i$.

Since $\left[y_i\right]_{s}$ is a deterministic function of the unconstrained variables $\left[y_i\right]_{\bar{x}}$ and $\left[y_i\right]_{\bar{s}}$, it becomes more efficient to eliminate $\left[y_i\right]_{s}$ from the search space and concatenate $\left[y_i\right]_{\bar{x}}$ and $\left[y_i\right]_{\bar{s}}$ into a single ``free'' variable $\bar{r}_i := \left(\left[y_i\right]_{\bar{x}},\left[y_i\right]_{\bar{s}} \right)$. Similar to the convention for $y_{i,e}$ and $y_{j,e}$, we denote $\left(\bar{r}_{i,e}, \bar{r}_{j,e}\right)$ and $\left(\bar{s}_{i,e}, \bar{s}_{j,e}\right)$ as the free variables and constrained state variables, respectively, shared between nodes $i$ and $j$. Then we can repose the sub-optimization Problem~\eqref{eq:sub-op-problem} in the following way. We let

\begin{align*}
\bar{f_i}\left(s_i,\bar{r}_i\right) := & f_i\left(\left[y\right]_{s}\right) - \\
        & \sum_{e \in E\left(i\right)}
        \Lambda_{i,e} \lambda^{k,T}_{e} \left(r_{i,e} - \bar{r}^{k}_{e} \right) +
        \frac{\augterm}{2} \|r_{i,e} - \bar{r}^{k}_{e}\|_2^2 + \\
        & \sum_{e \in E\left(i\right)}
        \Lambda_{i,e} \lambda^{k,T}_{e} \left(s_{i,e} - \bar{s}^{k}_{e} \right) +
        \frac{\augterm}{2} \|s_{i,e} - \bar{s}^{k}_{e}\|_2^2        
\end{align*}
be the ``augmented'' sub-objective accounting for the additional ADMM terms for subproblem $i$, where $\bar{r}_e,\bar{s}_e$ denotes the vector mean of $r_{i,e},r_{j,e}$ and $s_{i,e},s_{j,e}$ respectively. Also, if we let the concatenated subsystem equations be:

\[
H_i\left(s,r\right) :=s - g_i\left(\left[r\right]_{\bar{x}}, \left[r\right]_{\bar{s}} \right),
\]

then we have

\begin{align}
	\label{eq:sub-op-simple}
	\left(s^{k+1}_i, \bar{r}^{k+1}_i\right) & = \arg \min_{s,r} \bar{f}_i\left(s, r\right) \\ 
	\text{subject to:} & \quad H_i\left(s,r\right) = 0
\end{align}

The form of Problem~\eqref{eq:sub-op-simple} permits us to apply the \emph{discrete adjoint method} (Section~\ref{sec:discrete-adjoint-method}) to compute gradients of $\bar{f}_i$ at some search point $\bar{r}^0_i$. If we let $s^0_i$ be defined so that $H_i\left(s^0_i,\bar{r}_i^0\right) = 0$, then we arrive at the following expression for the gradient:

\begin{align}
	\label{eq:adjoint-grad-admm} \nabla_{r} \bar{f}_i\left(s^0_i,\bar{r}_i^0\right)  =  \gamma^T \frac{\partial H_i\left(s^0_i,\bar{r}_i^0\right)}{\partial r} & + \frac{\partial \bar{f}_i\left(s^0_i,\bar{r}_i^0\right)}{\partial r} \\ \text{subject to: } \quad \frac{\partial H_i\left(s^0_i,\bar{r}_i^0\right)}{\partial s}^T \gamma & = -\frac{\partial \bar{f}_i\left(s^0_i,\bar{r}_i^0\right)}{\partial s}^T, \label{eq:adjoint-system}
\end{align}

where $\gamma$ is the \emph{discrete adjoint} variable and Equation~\eqref{eq:adjoint-system} is the \emph{discrete adjoint} system.

\subsection{Distributed, Coordinated Optimal Ramp Metering and VSL} % (fold)
\label{sec:ramp-metering-admm}

We apply distributed optimization via subnetwork splitting to the problem of coordinated, predictive freeway onramp metering and VSL control~\cite{Papageorgiou1991,Frejo2011,Reilly2013AdjointBased,Muralidharana}, where traffic lights on freeway onramps are used to regulate the flow entering freeway mainlines and speed limits are dynamically adapted in order to prevent congestion and improve such metrics as driver travel time and speed variability. The term \emph{coordinated} indicates that many traffic lights and VSL signs along a freeway stretch will act cooperatively, given that conditions near one onramp or VSL sign may eventually affect conditions at a neighboring onramp or VSL sign. The term \emph{predictive} indicates that the metering/VSL strategy should anticipate future conditions on the roadway using traffic demand predictions and an underlying model of the evolution of the freeway system.

\begin{figure}
\subfloat[A single freeway junction near link $i$.]{
  \includegraphics[width=0.3\columnwidth]{previous-articles/admm/figures/vsl}
  \label{fig:freeway-labels}
} \hfill
\subfloat[Diagram of freeway network with A-ADMM subnetwork splitting.]{
  \includegraphics[width=0.6\columnwidth]{previous-articles/admm/figures/freeway-split-network-ln}
  \label{fig:overlapping-freeway}}
\caption[Overview of the freeway ramp metering network and state evolution and linear freeway network partitioning schemes.]{Overview of the freeway ramp metering network and state evolution. Figure~\ref{fig:freeway-labels} shows the dynamical state and control variables of a particular junction $i$ on the freeway. The relation between mainline density $\rho{[i,k]}$, onramp queues $l{[i,k]}$, metering control rate $c{[i,k]}$, VSL $\nu{[i,k]}$, and boundary condition split ratios $\beta{[i,k]}$ for a given time-step $k$ are depicted, and mathematically expressed in Equations~\eqref{eq:first-discrete}-\eqref{eq:last-discrete}.  Figure~\ref{fig:overlapping-freeway} shows how one may partition the linear network into subnetworks.   While subnetworks may have internal links and onramps, they will also include links and onramps immediately upstream and downstream as part of their shared state (denoted by the dashed-line boxes), giving the appearance of overlapping subnetworks.}
\label{fig:freeway}
\end{figure}

Similar to discretized freeway models following the cell transmission model (CTM) approach~\cite{daganzo1995cell} taken in~\cite{delle2014pde,Reilly2013AdjointBased}, we adopt the \emph{Link-Node} CTM model presented in~\cite{Muralidharana}. The network is given as a linear sequence of mainline link, onramp and offramp triples\footnote{Freeway models with more general network topologies exist~\cite{garavello2006traffic} and allow direct application of the subnetwork splitting method presented herewithin. We limit our discussion to linear freeway networks to simplify the presentation.}, as depicted in Figure~\ref{fig:freeway}. We establish the state variables of the system as $s=\{\rho\left[i,k\right],l\left[i,k\right] : i\in\left[1,N\right], k\in\left[1,T\right]\}$, where $\rho\left[i,k\right]$ is the number of vehicles on the mainline link $i$ (with unit length) and $l\left[i,k\right]$ is the number of vehicles queued on onramp $i$, both at time-step $k$. Additionally, the control variables are $x=\{(c\left[i,k\right], \nu\left[i,k\right]) : i\in\left[1,N\right], k\in\left[1,T\right]\}$, where $c\left[i,k\right]\in\Re_+$ is the maximum vehicles that can leave onramp $i$ at time $k$ (ramp metering rate), and $\nu\left[i,k\right]$ is the maximum speed of vehicles on link $i$ at time $k$ (VSL rate). The following system of equations relate the state of the freeway at time-step $k-1$ to $k$:

\begin{align}
  d\left[i,k\right] & = \min\left(c\left[i,k\right], l\left[i,k\right]\right) \label{eq:first-discrete} \\
  \sigma\left[i,k\right] & = \min\left(w \left(\rho^{\max} - \rho\left[i, k\right]\right), f^{\max}\right) \\
  \delta\left[i,k\right] & = \min\left(\nu\left[i,k\right]\rho\left[i,k\right], f^{\max}\right)\left(1 - \beta\left[i,k\right]\right) + d\left[i,k\right]\\
  f\left[i,k\right] & = \min\left(\nu\left[i,k\right]\rho\left[i,k\right], f^{\max}\right) \\
  & \times \frac{\min\left(\delta\left[i,k\right], \sigma\left[i+1,k\right]\right)}{\delta\left[i,k\right]} \nonumber \\
  r\left[i,k\right] &= d\left[i,k\right] \frac{\min\left(\delta\left[i-1,k\right], \sigma\left[i,k\right]\right)}{\delta\left[i-1,k\right]} \label{eq:last-intermediate} \\
  l\left[i,k\right] &= l\left[i,k-1\right] + D\left[i,k\right] - r\left[i,k-1\right] \label{eq:first-explicit}\\
  \rho\left[i,k\right] &= \rho\left[i,k-1\right] + f\left[i-1, k-1\right] (1 - \beta\left[i,k-1\right]) \label{eq:last-discrete} \\
  & + r\left[i,k-1\right] - f\left[i,k-1\right] \nonumber
\end{align}

The recursive definitions above require an initial condition,

\[
s^0=\{\rho^0\left[i\right], l^0\left[i\right]: i\in \left[1,N\right] \},
\]
and boundary conditions at the left and right extremes of the network,
\[
\left(s^L, s^R\right)=\{\left(s^L\left[k\right],s^R\left[k\right]\right):k\in \left[0,T\right]\},
\]
both of which are assumed given. Equations~\eqref{eq:first-discrete}-\eqref{eq:last-intermediate} can be seen as intermediate computations required to update the state variables given in Equations~\eqref{eq:first-explicit}-\eqref{eq:last-discrete}, and not explicitly part of the state vector. We note that the offramps are modeled as stateless, infinite-capacity sinks, and thus are only captured through $\beta\left[i,k\right]$, the fraction of vehicles which desire to exit offramp $i$ rather than continue to mainline link $i+1$ at time-step $k$. A diagram of the state and control variables for a single junction is given in Figure~\ref{fig:freeway-labels}. The above dynamics are non-convex, but it is shown in~\cite{Muralidharana} that, assuming some maximum velocity $V$ and ramp flow $C$, if a set of variables satisfy the following linear inequalities and equalities:

\begin{align}
f\left[i,k\right] & \le \min\left(\rho\left[i,k\right] V, f^{\max} \right) \label{eq:relax1}\\
f\left[i, k\right] & (1 - \beta\left[i+1,k\right]) + r\left[i+1,k\right] \\
 & \le \min\left(w\left(\rho^{\max} - \rho\left[i+1,k\right]\right), f^{\max}\right) \nonumber \\
r\left[i,k\right] &  \le \min\left(C, l\left[i,k\right]\right) \label{eq:relax2} \\
& \text{Eqns}~\eqref{eq:first-explicit}-\eqref{eq:last-discrete}, \nonumber
\end{align}

then a control $c,\nu$ can be constructed such that $f,r,\rho, l, c, \nu$ satisfy Equations~\eqref{eq:first-discrete}-\eqref{eq:last-discrete}. Thus, we can employ the adjoint method presented in Section~\ref{sec:minimizing_sub_objectives_using_the_adjoint_method} on the relaxed problem in order to improve sub-objectives during each iteration of the A-ADMM algorithm with a guarantee of convergence to the global optimum. We omit the explicit $c,\nu$ reconstruction procedure and refer the reader to~\cite{Muralidharana} for details.

As an objective, we use \emph{total travel time}, or the cumulative time spent by all vehicles on the network. Total travel time is mathematically expressed as
\[
f_{\text{TTT}} = \sum_{i,k} \rho\left[i,k\right] + l\left[i,k\right],
\] and is decomposable across subnetwork splits.

It is clear from the definitions of $s$ and $x$ above that each state variable is a direct function of only the state and control variables of neighboring links at the previous time-step, and as such, can be decomposed using the subnetwork splitting method in Section~\ref{sec:distributed_optimization_of_coupled_dynamical_systems}. Figure~\ref{fig:overlapping-freeway} depicts such a splitting, where each subnetwork also includes the neighboring upstream and downstream links as boundary conditions.

The dependency graph $\left(V,E\right)$ for such a network has a natural structure, where an edge $(i,j)$ is in $E$ if and only if $j=i+1$, and thus a subnetwork need only communicate with the linear subnetworks immediately upstream and downstream of itself. Furthermore, only information pertaining to the bordering links and onramps of a subnetwork needs to be shared with its neighbors, allowing a subnetwork to conceal the particular implementation of its internal freeway model from the rest of the system.


\subsection{Numerical Results}
\label{sec:numerical_results-admm}

\paragraph{Convergence with Number of Subnetworks}

\begin{figure}[t]
  \centering
  \includegraphics[width=\columnwidth]{previous-articles/admm/figures-lowres/bcScen/spacetime}
  \caption[Space-time diagrams of mainline and onramp vehicle count evolution for 12 mile network depicting large congestion pockets being reduced using coordinated holding of vehicles on onramps and decreased speed limits during periods of congestion.]{Space-time diagrams of mainline (row 1) and onramp (row 2) vehicle count evolution for 12 mile network. Large congestion pockets appearing for (A) no control case are reduced using coordinated holding of vehicles on onramps and decreased speed limits during periods of congestion (C). Lack of communication between subsystems (B) leads to an ineffective control policy.}
  \label{fig:spacetime}
\end{figure}

We first investigate the numerical convergence of the A-ADMM metering and VSL controller on a model 4-lane freeway network spanning 12 miles ($N=12$) with 3 onramps and 2 offramps over a 2 hour simulation ($T=120$). We consider three different partitionings by splitting the network into 2, 3 and 4 subnetworks, respectively. We also simulated the following alternative controllers for comparison:

\begin{itemize}
  \item No control: Metering rates are set to maximum ramp flux rates $C$ and speeds are set to free flow velocity $V$.
  \item Centralized: A single optimal control problem over the entire freeway is solved as a convex optimization problem. This solution gives the theoretical lower bound on total travel time.
  \item No communication: Individual subnetworks optimize over their own decomposed total travel time objective, with no exchange of information between subnetworks.
  \item Communicative: Subnetworks iteratively optimize over decomposed objectives and exchange the resulting predicted boundary conditions with neighbors until resulting boundary conditions converge (see~\cite{Frejo2011}). There is no guarantee of convergence of boundary conditions or of finding the global optimum.
\end{itemize}

Figure~\ref{fig:spacetime} gives a space-time depiction of the mainline and onramp vehicle evolution for the no control, no communication, and A-ADMM controllers.

\begin{figure}[t]
  \centering
  \includegraphics[width=.7\columnwidth]{previous-articles/admm/figures-lowres/bcScen/runtime}
  \caption{Total travel time vs. computation time for several different different control schemes and subnetwork (SN) partitionings. The no-communication results are omitted due to poor performance.}
  \label{fig:runtime}
\end{figure}

The convergence results for the 12 mile freeway network are summarized in Figure~\ref{fig:runtime}. The centralized approach is faster than the distributed approaches (A-ADMM and communicative) as the former does not require an outer communication loop. As the number of network partitions increases, A-ADMM converges faster to the optimum due to the parallelization of the subnetwork optimizations. Furthermore, the communicative algorithm degrades in performance with increasing number of partitions due to the increase in communication requirements and lack of global objective coordination. If a decentralized algorithm is required for architectural reasons, then the A-ADMM approach is shown to be most desirable due to the lower degree of coordination than the centralized approach and better convergence than the communicative approach.

\paragraph{Distributed MPC for I15 Network}

\begin{figure}[ht]
  \centering
  \subfloat[Geographical depiction.]{
  \label{sub:i15}%
  \includegraphics[width=.7\columnwidth]{previous-articles/admm/figures/15}%
  } \\
  \subfloat[Total travel time summary in 1000 vehicle hours.]{
  \footnotesize
    \begin{tabular}{|c|c|c|c|c|c|}
    \hline
    Opt. & No Con. & Cent. MPC & No Comm. & Comm. & A-ADMM \\ \hline
    2.572 & 2.605  & 2.584 & 4.529 & 8.453 & 2.589 \\ \hline
    \end{tabular}\label{tab:i15}}
    \caption[I15 South MPC simulation summary for distributed A-ADMM controller.]{I15 South MPC simulation summary. Figure~\ref{sub:i15} shows the freeway under consideration partitioned into 5 subnetworks, while Table~\ref{tab:i15} gives a summary of the performance of the different ramp metering/VSL controllers.}
    \label{fig:i15-admm}
\end{figure}

MPC simulations were run on a calibrated model of the I15 South freeway in San Diego, CA with boundary flow data taken from measurements recording during a morning rush hour. The simulation spans 20 miles ($N=32$), contains 9 onramps and runs over a 170 minute window ($T=1000$) with an MPC update time of 17 minutes and a horizon of 25 minutes. The network is partitioned into 5 subnetworks and is depicted geographically in Figure~\ref{sub:i15}.

Table~\ref{tab:i15} gives a summary of the performance of the A-ADMM MPC controller along with other controllers. The results indicate that the A-ADMM controller performs nearly as well as the centralized MPC controller, which can be viewed as a lower-bound on the performance of MPC controllers with limited horizons. The communicative approach performed worse than the non-communicative approach because its iterative terminated after reaching a set number iterations on a highly inefficient solution, due to its lack of convergence guarantees.

\section*{Acknowledgments}

We would like to acknowledge Professor Roberto Horowitz, Dr. Gabriel Gomes, and Dr. Ajith Muralidharan of UC Berkeley for their work on linear formulations of freeway optimal control problems~\cite{gomes2006optimal,Muralidharana} which greatly improved the practical nature of the theory developed within this work.